{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import progressbar\n",
    "\n",
    "taxonomy = pd.read_excel('./taxonomy/gene_catalog_taxonomy.xlsx')\n",
    "ardb = pd.read_excel('./ARDB/gene_catalog_ardb_annotation.xlsx')\n",
    "\n",
    "#修改lsts中内容\n",
    "lsts = ['AC1','AC2','AC3']\n",
    "annotations = ['integrase','IS','plasmid','RepBase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "widgets = [\n",
    "     '匹配: ', progressbar.Percentage(),  # 进度条标题\n",
    "     ' ', progressbar.Bar(marker='#', left='[', right=']', fill=' '),  # 进度条填充、边缘字符\n",
    "     ' ', progressbar.Timer(),  # 已用的时间\n",
    "     ' ', progressbar.ETA(),  # 剩余时间\n",
    "     ' ', progressbar.FileTransferSpeed(),  # 下载速度\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_Excel_Data(excel_path, name_data,folder='PROCESS'):\n",
    "    # 将excel的数据切割开，按照做实验中gene顺序分成四个文件\n",
    "    widgets = [\n",
    "     '分割: ', progressbar.Percentage(),  # 进度条标题\n",
    "     ' ', progressbar.Bar(marker='#', left='[', right=']', fill=' '),  # 进度条填充、边缘字符\n",
    "     ' ', progressbar.Timer(),  # 已用的时间\n",
    "     ' ', progressbar.ETA(),  # 剩余时间\n",
    "     ' ', progressbar.FileTransferSpeed(),  # 下载速度\n",
    "    ]\n",
    "    Excel_data = pd.read_excel(excel_path)\n",
    "    Excel_data['num_G'] = Excel_data['#Gene'].map(lambda x:x.split('_')[0])\n",
    "    bar = progressbar.ProgressBar(widgets = widgets)\n",
    "    for i in bar(Excel_data['num_G'].unique()):\n",
    "        Excel_data_i = Excel_data.loc[Excel_data['num_G'] == i]\n",
    "        Excel_data_i.drop('num_G',axis=1)\n",
    "        excel_name = '{}_'.format(i) + name_data + '.csv'\n",
    "        Excel_data_i[['#Gene']].to_csv('./{}/{}'.format(folder,excel_name))\n",
    "    \n",
    "\n",
    "def ardb_orf_get_fas(i):\n",
    "    with open('./ORF/{}.orf.ffn'.format(i), 'r+') as o:\n",
    "        orf = o.readlines()\n",
    "    with open('./CONTIG/{}.assembly.fas'.format(i), 'r+') as f:\n",
    "        fas = f.readlines()\n",
    "    fas_data = pd.DataFrame(fas[1::2], columns=['sequence'])\n",
    "    fas_data['fas'] = np.array(fas[0::2])\n",
    "    fas_data['fas'] = fas_data.fas.map(lambda x: x.split(' ')[0].split('>')[1])\n",
    "\n",
    "    orf_data = pd.DataFrame(orf[1::2], columns=['sequence'])\n",
    "    orf_data['#Gene'] = np.array(orf[0::2])\n",
    "    orf_data['#Gene'] = orf_data['#Gene'].map(lambda x: x.split(' ')[0].split('>')[1].split('\\n')[0])\n",
    "    orf_data['sequence'] = orf_data['sequence'].map(lambda x: x.split('\\n')[0])\n",
    "    ardb_data = pd.read_csv('./ARDB/{}_ardb.csv'.format(i))[['#Gene']]\n",
    "    ardb_data_orf = pd.merge(ardb_data,orf_data,on='#Gene',how='left')\n",
    "    ardb_data_orf['fas'] = -1\n",
    "    ardb_data_orf['p_or_n'] = 1\n",
    "    ardb_data_orf['sequence_n'] = 0\n",
    "    ardb_data_orf['sequence_n'] = ardb_data_orf['sequence'].map(lambda x:x[-1::-1])\n",
    "    ardb_data_orf['sequence_n'] = ardb_data_orf['sequence_n'].map(lambda x:x.replace('A','1').replace('T','2').replace('G','3').replace('C','4'))\n",
    "    ardb_data_orf['sequence_n'] = ardb_data_orf['sequence_n'].map(lambda x:x.replace('1','T').replace('2','A').replace('3','C').replace('4','G'))\n",
    "\n",
    "    s = ''.join(fas_data['sequence'].tolist())\n",
    "    bar = progressbar.ProgressBar(widgets = widgets,maxval=len(ardb_data_orf['sequence']))\n",
    "    bar.start()\n",
    "    for j,val in enumerate(ardb_data_orf['sequence']):\n",
    "        if val in s:\n",
    "            ardb_data_orf['fas'].loc[j] = fas_data['fas'].loc[s[:s.find(val)].count('\\n')]\n",
    "        elif ardb_data_orf['sequence_n'].loc[j] in s:\n",
    "            ardb_data_orf['fas'].loc[j] = fas_data['fas'].loc[s[:s.find(ardb_data_orf['sequence_n'].loc[j])].count('\\n')]\n",
    "            ardb_data_orf['p_or_n'].loc[j] = -1\n",
    "        bar.update(j)\n",
    "    bar.finish()\n",
    "\n",
    "    ardb_data_orf['orf_begin'] = -1\n",
    "    ardb_data_orf['orf_end'] = -1\n",
    "    for j,val in enumerate(ardb_data_orf['sequence']):\n",
    "        if ardb_data_orf['p_or_n'].loc[j] == 1:\n",
    "            orf_sequence = val\n",
    "            ardb_data_orf['orf_begin'].loc[j] = fas_data['sequence'].loc[fas_data['fas']==ardb_data_orf['fas'].loc[j]].values[0].find(orf_sequence)   \n",
    "        elif ardb_data_orf['p_or_n'].loc[j] == -1:\n",
    "            orf_sequence = ardb_data_orf['sequence_n'].loc[j]\n",
    "            ardb_data_orf['orf_begin'].loc[j] = fas_data['sequence'].loc[fas_data['fas']==ardb_data_orf['fas'].loc[j]].values[0].find(orf_sequence)   \n",
    "        ardb_data_orf['orf_end'].loc[j] = ardb_data_orf['orf_begin'].loc[j] + len(orf_sequence)\n",
    "    ardb_data_orf.to_csv('./PROCESS/{}_orf_fas.csv'.format(i))   \n",
    "    \n",
    "def all_orf_get_fas(i,folder_name='taxonomy',filename='all'):\n",
    "    with open('./ORF/{}.orf.ffn'.format(i), 'r+') as o:\n",
    "        orf = o.readlines()\n",
    "    with open('./CONTIG/{}.assembly.fas'.format(i), 'r+') as f:\n",
    "        fas = f.readlines()\n",
    "    fas_data = pd.DataFrame(fas[1::2], columns=['sequence'])\n",
    "    fas_data['fas'] = np.array(fas[0::2])\n",
    "    fas_data['fas'] = fas_data.fas.map(lambda x: x.split(' ')[0].split('>')[1])\n",
    "    orf_data = pd.DataFrame(orf[1::2], columns=['sequence'])\n",
    "    orf_data['#Gene'] = np.array(orf[0::2])\n",
    "    orf_data['#Gene'] = orf_data['#Gene'].map(lambda x: x.split(' ')[0].split('>')[1].split('\\n')[0])\n",
    "    orf_data['fas'] = -1\n",
    "    orf_data.dropna(inplace=True)\n",
    "    orf_data['sequence'] = orf_data['sequence'].map(lambda x:x.split('\\n')[0])\n",
    "    orf_data['p_or_n'] = 1\n",
    "    orf_data['sequence_n'] = 0\n",
    "    orf_data['sequence_n'] = orf_data['sequence'].map(lambda x:x[-1::-1])\n",
    "    orf_data['sequence_n'] = orf_data['sequence_n'].map(lambda x:x.replace('A','1').replace('T','2').replace('G','3').replace('C','4'))\n",
    "    orf_data['sequence_n'] = orf_data['sequence_n'].map(lambda x:x.replace('1','T').replace('2','A').replace('3','C').replace('4','G'))\n",
    "    \n",
    "    data = pd.read_csv('./PROCESS/{}_orf_fas.csv'.format(i))\n",
    "    data = data.drop(['Unnamed: 0'], axis=1)\n",
    "    data = data.loc[data['fas'] != '-1']\n",
    "    fas = pd.merge(pd.DataFrame(data.fas.unique(), columns=['fas']), fas_data, on='fas', how='left')\n",
    "    s = ''.join(fas['sequence'].tolist())\n",
    "    bar = progressbar.ProgressBar(widgets = widgets,maxval=len(orf_data['sequence']))\n",
    "    bar.start()\n",
    "    for j,val in enumerate(orf_data['sequence']):\n",
    "        if val in s:\n",
    "            orf_data['fas'].loc[j] = fas['fas'].loc[s[:s.find(val)].count('\\n')]\n",
    "        elif orf_data['sequence_n'].loc[j] in s:\n",
    "            orf_data['fas'].loc[j] = fas['fas'].loc[s[:s.find(orf_data['sequence_n'].loc[j])].count('\\n')]\n",
    "            orf_data['p_or_n'].loc[j] = -1\n",
    "        bar.update(j)\n",
    "    bar.finish()\n",
    "    orf_data['orf_begin'] = -1\n",
    "    orf_data['orf_end'] = -1\n",
    "    for j,val in enumerate(orf_data['sequence']):\n",
    "        if orf_data['fas'].loc[j] != -1 and orf_data['fas'].loc[j] != '-1':\n",
    "            if orf_data['p_or_n'].loc[j] == 1:\n",
    "                orf_sequence = val\n",
    "                orf_data['orf_begin'].loc[j] = fas['sequence'].loc[fas['fas']==orf_data['fas'].loc[j]].values[0].find(orf_sequence)   \n",
    "                if orf_data['orf_begin'].loc[j] == -1:\n",
    "                    print(j)\n",
    "            elif orf_data['p_or_n'].loc[j] == -1:\n",
    "                orf_sequence = orf_data['sequence_n'].loc[j]\n",
    "                orf_data['orf_begin'].loc[j] = fas['sequence'].loc[fas['fas']==orf_data['fas'].loc[j]].values[0].find(orf_sequence)\n",
    "                if orf_data['orf_begin'].loc[j] == -1:\n",
    "                    print(orf_sequence)\n",
    "            orf_data['orf_end'].loc[j] = orf_data['orf_begin'].loc[j] + len(orf_sequence)\n",
    "    orf_data = orf_data.loc[orf_data['fas'] != -1]\n",
    "    orf_data = orf_data.loc[orf_data['fas'] != '-1']\n",
    "    orf_data.to_csv('./PROCESS/{}_all_fas.csv'.format(i,filename))\n",
    "\n",
    "def merge_data(i,annotations):\n",
    "    orf_fas = pd.read_csv('./PROCESS/{}_orf_fas.csv'.format(i))\n",
    "    orf_fas = orf_fas.drop(['Unnamed: 0'],axis=1)\n",
    "    ardb_data = pd.merge(orf_fas,ardb,on='#Gene')\n",
    "    all_fas = pd.read_csv('./PROCESS/{}_all_fas.csv'.format(i))\n",
    "    all_fas = all_fas.drop(['Unnamed: 0'],axis=1)\n",
    "    for annotation in annotations:\n",
    "        mge = pd.read_excel('./MGE/{}_annotation.xlsx'.format(annotation))\n",
    "        mge_data = pd.merge(mge,all_fas,on='#Gene')\n",
    "        mge_data.drop(['sequence','sequence_n'],axis=1,inplace=True)\n",
    "        mge_data = mge_data.loc[mge_data['fas'] != '-1']\n",
    "        mge_data = mge_data.loc[mge_data['fas'] != -1]\n",
    "        mge_data = mge_data.rename(columns = {'#Gene':'{}_Gene'.format(annotation),\n",
    "                                              'orf_begin':'{}_orf_begin'.format(annotation),\n",
    "                                              'orf_end':'{}_orf_end'.format(annotation),\n",
    "                                              'p_or_n':'{}_p_or_n'.format(annotation)})\n",
    "        ardb_data = pd.merge(ardb_data,mge_data,on='fas',how='left')\n",
    "    taxonomy_data = pd.read_csv('./taxonomy/{}_taxonomy.csv'.format(i))\n",
    "    taxonomy_data = taxonomy_data.drop(['Unnamed: 0'],axis=1)\n",
    "    taxonomy_data = pd.merge(taxonomy_data,all_fas,on='#Gene')\n",
    "    taxonomy_data = pd.merge(taxonomy_data,taxonomy,on='#Gene',how='left')\n",
    "    taxonomy_data.drop(['sequence','sequence_n'],axis=1,inplace=True)\n",
    "    taxonomy_data = taxonomy_data.rename(columns = {'#Gene':'taxonomy_Gene',\n",
    "                                              'orf_begin':'taxonomy_orf_begin',\n",
    "                                              'orf_end':'taxonomy_orf_end',\n",
    "                                              'p_or_n':'taxonomy_p_or_n'})\n",
    "    taxonomy_data = taxonomy_data.loc[taxonomy_data.fas != -1]\n",
    "    taxonomy_data = taxonomy_data.loc[taxonomy_data.fas != '-1']\n",
    "    taxonomy_data['count'] = taxonomy_data['Species']\n",
    "    taxonomy_count = pd.DataFrame(taxonomy_data.groupby(['fas','Species']).agg({'count': 'count'}))\n",
    "    taxonomy_count = taxonomy_count.reset_index()\n",
    "    taxonomy_count = pd.merge(taxonomy_count, taxonomy_count.groupby('fas', as_index=False)['count'].sum(), on='fas', how='left')\n",
    "    taxonomy_count.columns = ['fas','Species','count','sum']\n",
    "    taxonomy_count['avg'] = taxonomy_count['count'] / taxonomy_count['sum']\n",
    "    taxonomy_count_data = pd.merge(taxonomy_count.loc[taxonomy_count.avg > 0.5], taxonomy_data, on=['fas', 'Species'], how='left')\n",
    "    taxonomy_count_data = taxonomy_count_data.drop(['count_x', 'count_y', 'sum', 'avg'], axis=1)\n",
    "    ardb_data = pd.merge(ardb_data,taxonomy_count_data,on='fas',how='left')\n",
    "    ardb_data.drop(['sequence','sequence_n'],axis=1,inplace=True)\n",
    "    ardb_data.to_csv('./final/ardb_data_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "分割: 100% [####################] Elapsed Time: 0:00:00 Time: 0:00:00 229.36  B/s\n",
      "分割: 100% [####################] Elapsed Time: 0:00:00 Time: 0:00:00 288.98  B/s\n"
     ]
    }
   ],
   "source": [
    "Split_Excel_Data('./taxonomy/gene_catalog_taxonomy.xlsx',name_data='taxonomy',folder='taxonomy')\n",
    "Split_Excel_Data('./ARDB/gene_catalog_ardb_annotation.xlsx',name_data='ardb',folder='ARDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "匹配: 100% [####################] Elapsed Time: 0:16:21 Time: 0:16:21   0.79  B/s\n",
      "匹配: 100% [####################] Elapsed Time: 6:54:27 Time: 6:54:27  17.64  B/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并成功\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "匹配: 100% [####################] Elapsed Time: 0:19:11 Time: 0:19:11   0.71  B/s\n",
      "匹配: 100% [####################] Elapsed Time: 7:42:27 Time: 7:42:27  20.13  B/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并成功\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "匹配: 100% [####################] Elapsed Time: 0:13:16 Time: 0:13:16   0.79  B/s\n",
      "匹配: 100% [####################] Elapsed Time: 4:11:46 Time: 4:11:46  31.73  B/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并成功\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# with ProcessPoolExecutor(max_workers=1) as executor:\n",
    "#     futures = [executor.submit(ardb_orf_get_fas,lst)\n",
    "#               for lst in lsts]\n",
    "# # print('成功完成匹配')\n",
    "for lst in lsts:\n",
    "    ardb_orf_get_fas(lst)\n",
    "    all_orf_get_fas(lst)\n",
    "    merge_data(lst,annotations)\n",
    "    print('合并成功'.format(lst))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lsts:\n",
    "    ardb_data = pd.read_csv('./final/ardb_data_{}.csv'.format(i))\n",
    "    ardb_data = ardb_data.drop('Unnamed: 0',axis=1)\n",
    "    ardb_data = ardb_data.loc[ardb_data.fas!=-1]\n",
    "    ardb_data = ardb_data.loc[ardb_data.fas!='-1']\n",
    "    ardb_data.to_csv('./final/not_null/ardb_data_not_null_{}.csv'.format(i))\n",
    "    \n",
    "    ardb_data_species = ardb_data.loc[ardb_data.Species.notnull()]\n",
    "    ardb_data_species.to_csv('./final/species/ardb_data_species_{}.csv'.format(i))\n",
    "    \n",
    "    ardb_data_mge = pd.DataFrame(columns = ardb_data.columns)\n",
    "    for j in annotations:\n",
    "        if '{}_Gene'.format(j) in ardb_data.columns:\n",
    "            ardb_data_mge = pd.concat([ardb_data_mge,ardb_data.loc[ardb_data['{}_Gene'.format(j)].notnull()]],axis=0)\n",
    "    ardb_data_mge.to_csv('./final/mge/ardb_data_mge_{}.csv'.format(i))\n",
    "    \n",
    "    ardb_data = pd.read_csv('./final/ardb_data_{}.csv'.format(i))\n",
    "    ardb_data.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    ardb_data_more_2 = pd.DataFrame(ardb_data.fas.value_counts())\n",
    "    ardb_data_more_2 = ardb_data_more_2.loc[ardb_data_more_2.fas>=2].reset_index()\n",
    "    ardb_data_more_2.columns = ['fas','count']\n",
    "    ardb_data_more_2.drop('count',axis=1,inplace=True)\n",
    "    ardb_data_more = pd.merge(ardb_data_more_2,ardb_data,on='fas',how='left')\n",
    "    \n",
    "    ardb_data_more.to_csv('./final/more_2_ardb/ardb_data_more_2_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lsts:\n",
    "    all_fas = pd.read_csv('./PROCESS/{}_all_fas.csv'.format(i))\n",
    "    ardb_data = pd.read_csv('./final/ardb_data_{}.csv'.format(i))\n",
    "    all_fas = all_fas.drop(['Unnamed: 0', 'sequence', 'sequence_n'], axis = 1)\n",
    "    ardb_data = ardb_data.drop(['Unnamed: 0'], axis = 1)\n",
    "    ardb_data = ardb_data.rename(columns = {'#Gene':'ardb_Gene',\n",
    "                                              'orf_begin':'ardb_orf_begin',\n",
    "                                              'orf_end':'ardb_orf_end',\n",
    "                                              'p_or_n':'ardb_p_or_n'})\n",
    "    all_fas = pd.merge(all_fas, ardb_data, on='fas')\n",
    "    all_fas.to_csv('./final/all_fas_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Gene</th>\n",
       "      <th>fas</th>\n",
       "      <th>p_or_n</th>\n",
       "      <th>orf_begin</th>\n",
       "      <th>orf_end</th>\n",
       "      <th>ardb_Gene</th>\n",
       "      <th>ardb_p_or_n</th>\n",
       "      <th>ardb_orf_begin</th>\n",
       "      <th>ardb_orf_end</th>\n",
       "      <th>SARG</th>\n",
       "      <th>...</th>\n",
       "      <th>taxonomy_orf_begin</th>\n",
       "      <th>taxonomy_orf_end</th>\n",
       "      <th>taxonomy_Gene</th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC3_orf_997</td>\n",
       "      <td>k141_396721</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>AC3_orf_997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>bacitracin__bacA_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC3_orf_998</td>\n",
       "      <td>k141_396721</td>\n",
       "      <td>-1</td>\n",
       "      <td>510</td>\n",
       "      <td>954</td>\n",
       "      <td>AC3_orf_997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>bacitracin__bacA_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC3_orf_2000</td>\n",
       "      <td>k141_170054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>263</td>\n",
       "      <td>AC3_orf_2028</td>\n",
       "      <td>1</td>\n",
       "      <td>30173</td>\n",
       "      <td>31910</td>\n",
       "      <td>multidrug__multidrug_ABC_transporter_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC3_orf_2001</td>\n",
       "      <td>k141_170054</td>\n",
       "      <td>-1</td>\n",
       "      <td>369</td>\n",
       "      <td>3882</td>\n",
       "      <td>AC3_orf_2028</td>\n",
       "      <td>1</td>\n",
       "      <td>30173</td>\n",
       "      <td>31910</td>\n",
       "      <td>multidrug__multidrug_ABC_transporter_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC3_orf_2002</td>\n",
       "      <td>k141_170054</td>\n",
       "      <td>-1</td>\n",
       "      <td>3871</td>\n",
       "      <td>5623</td>\n",
       "      <td>AC3_orf_2028</td>\n",
       "      <td>1</td>\n",
       "      <td>30173</td>\n",
       "      <td>31910</td>\n",
       "      <td>multidrug__multidrug_ABC_transporter_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>AC3_orf_476324</td>\n",
       "      <td>k141_169969</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>AC3_orf_476326</td>\n",
       "      <td>-1</td>\n",
       "      <td>807</td>\n",
       "      <td>2169</td>\n",
       "      <td>multidrug__mdtK_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>AC3_orf_476325</td>\n",
       "      <td>k141_169969</td>\n",
       "      <td>-1</td>\n",
       "      <td>468</td>\n",
       "      <td>771</td>\n",
       "      <td>AC3_orf_476326</td>\n",
       "      <td>-1</td>\n",
       "      <td>807</td>\n",
       "      <td>2169</td>\n",
       "      <td>multidrug__mdtK_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>AC3_orf_476326</td>\n",
       "      <td>k141_169969</td>\n",
       "      <td>-1</td>\n",
       "      <td>807</td>\n",
       "      <td>2169</td>\n",
       "      <td>AC3_orf_476326</td>\n",
       "      <td>-1</td>\n",
       "      <td>807</td>\n",
       "      <td>2169</td>\n",
       "      <td>multidrug__mdtK_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>AC3_orf_476327</td>\n",
       "      <td>k141_169969</td>\n",
       "      <td>-1</td>\n",
       "      <td>2172</td>\n",
       "      <td>3234</td>\n",
       "      <td>AC3_orf_476326</td>\n",
       "      <td>-1</td>\n",
       "      <td>807</td>\n",
       "      <td>2169</td>\n",
       "      <td>multidrug__mdtK_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>AC3_orf_478291</td>\n",
       "      <td>k141_155842</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>770</td>\n",
       "      <td>AC3_orf_478291</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>770</td>\n",
       "      <td>multidrug__mdtK_train_msa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5279 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               #Gene          fas  p_or_n  orf_begin  orf_end       ardb_Gene  \\\n",
       "0        AC3_orf_997  k141_396721       1          1      454     AC3_orf_997   \n",
       "1        AC3_orf_998  k141_396721      -1        510      954     AC3_orf_997   \n",
       "2       AC3_orf_2000  k141_170054      -1          2      263    AC3_orf_2028   \n",
       "3       AC3_orf_2001  k141_170054      -1        369     3882    AC3_orf_2028   \n",
       "4       AC3_orf_2002  k141_170054      -1       3871     5623    AC3_orf_2028   \n",
       "...              ...          ...     ...        ...      ...             ...   \n",
       "5274  AC3_orf_476324  k141_169969       1          1      439  AC3_orf_476326   \n",
       "5275  AC3_orf_476325  k141_169969      -1        468      771  AC3_orf_476326   \n",
       "5276  AC3_orf_476326  k141_169969      -1        807     2169  AC3_orf_476326   \n",
       "5277  AC3_orf_476327  k141_169969      -1       2172     3234  AC3_orf_476326   \n",
       "5278  AC3_orf_478291  k141_155842      -1          2      770  AC3_orf_478291   \n",
       "\n",
       "      ardb_p_or_n  ardb_orf_begin  ardb_orf_end  \\\n",
       "0               1               1           454   \n",
       "1               1               1           454   \n",
       "2               1           30173         31910   \n",
       "3               1           30173         31910   \n",
       "4               1           30173         31910   \n",
       "...           ...             ...           ...   \n",
       "5274           -1             807          2169   \n",
       "5275           -1             807          2169   \n",
       "5276           -1             807          2169   \n",
       "5277           -1             807          2169   \n",
       "5278           -1               2           770   \n",
       "\n",
       "                                                SARG  ...  taxonomy_orf_begin  \\\n",
       "0                         bacitracin__bacA_train_msa  ...                 NaN   \n",
       "1                         bacitracin__bacA_train_msa  ...                 NaN   \n",
       "2     multidrug__multidrug_ABC_transporter_train_msa  ...                 NaN   \n",
       "3     multidrug__multidrug_ABC_transporter_train_msa  ...                 NaN   \n",
       "4     multidrug__multidrug_ABC_transporter_train_msa  ...                 NaN   \n",
       "...                                              ...  ...                 ...   \n",
       "5274                       multidrug__mdtK_train_msa  ...                 NaN   \n",
       "5275                       multidrug__mdtK_train_msa  ...                 NaN   \n",
       "5276                       multidrug__mdtK_train_msa  ...                 NaN   \n",
       "5277                       multidrug__mdtK_train_msa  ...                 NaN   \n",
       "5278                       multidrug__mdtK_train_msa  ...                 NaN   \n",
       "\n",
       "      taxonomy_orf_end  taxonomy_Gene  Kingdom  Phylum  Class  Order  Family  \\\n",
       "0                  NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "1                  NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "2                  NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "3                  NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "4                  NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "...                ...            ...      ...     ...    ...    ...     ...   \n",
       "5274               NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "5275               NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "5276               NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "5277               NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "5278               NaN            NaN      NaN     NaN    NaN    NaN     NaN   \n",
       "\n",
       "      Genus  Species  \n",
       "0       NaN      NaN  \n",
       "1       NaN      NaN  \n",
       "2       NaN      NaN  \n",
       "3       NaN      NaN  \n",
       "4       NaN      NaN  \n",
       "...     ...      ...  \n",
       "5274    NaN      NaN  \n",
       "5275    NaN      NaN  \n",
       "5276    NaN      NaN  \n",
       "5277    NaN      NaN  \n",
       "5278    NaN      NaN  \n",
       "\n",
       "[5279 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
